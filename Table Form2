import requests
import pandas as pd
from bs4 import BeautifulSoup 

BaseUrl = 'xxxxxxxxxxx'

count = 1
links = []
docs = []

while True:
    Url = BaseUrl+'/4637/list%s.htm'%count

    html = requests.get(Url)
    html.encoding = 'utf-8'

    soup = BeautifulSoup(html.text,'lxml')
    for sou in soup.select('.Article_Title'):       
        for so in sou('a'):
            s = BaseUrl+so['href']
            links.append(s) 

            docs.append(so.text)
    count += 1
    if count > 2:
        break
        
df1 = pd.DataFrame(links)
df2 = pd.DataFrame(docs,columns = ['年份查询'])
df2['链接地址'] = df1
df2.to_csv('MainPage.csv',encoding='utf-8-sig')
print 'Save successful'
    
